# Crawling data from Yelp

import re
import util
import bs4
import queue
import json
import sys
import csv
import pandas as pd

# start from cook county cities
with open(r"c:\Users\35653\Desktop\CS122\project\cook_county_zips.csv") as cook_zips:
    reader = csv.reader(cook_zips)

    city_state = [(row[4], row[5]) for row in reader]
    del city_state[0]
    city_state = set(city_state)
    #print(len(city_state))

    cook_zips.close()

#print(city_state)
url_list = []
for city, state in city_state:
    html = "https://www.yelp.com/search?find_desc=Restaurants&find_loc=" + city + "%2C%20" + state
    url_list.append(html)

#for url in request_list:
#    print(url)

page_suffix = [i for i in range(0, 231, 10)]

for url in url_list:
    request = util.get_request(url)
    text = util.read_request(request)

    soup = bs4.BeautifulSoup(text, "html5lib")
    tags = soup.find_all('a', href=True, target="", role="")

    # extract href links to restaurants
    links = []
    for tag in tags:  
        link = tag['href']
        link = util.convert_if_relative_url(url, link)
        link = util.remove_fragment(link)
        # Hardcoded filter
        if link[-11:] == "Restaurants":
            if tag["name"] != '':
                for suffix in page_suffix:
                    link = link + "&start=" + str(suffix)
                if link not in links:
                    links.append(link)

with open(r"c:\Users\35653\Desktop\CS122\project\links.txt", "w") as write_file:
    write_file.writelines(links)

    write_file.close
'''
count = 0
for link in links:
    if count <= 5:
        print(link)
        count += 1
'''

#print(len(links))

#https://www.yelp.com/search?find_desc=Restaurants&find_loc=Blue%20Island%2C%20IL
#https://www.yelp.com/search?find_desc=Restaurants&find_loc=Blue%20Island%2C%20IL&start=10
#https://www.yelp.com/search?find_desc=Restaurants&find_loc=Blue%20Island%2C%20IL&start=20

#https://www.yelp.com/search?find_desc=&find_loc=Adel%2C%20GA


'''
# start from searching "Restaurant", "Chicago" from yelp main page
url = 'https://www.yelp.com/search?find_desc=Restaurants&find_loc=Chicago%2C%20IL&start=0'
request = util.get_request(url)
text = util.read_request(request)

soup = bs4.BeautifulSoup(text, "html5lib")
tags = soup.find_all('a', href=True, target="", role="")

# extract href links to restaurants
links = []
for tag in tags:  
    link = tag['href']
    link = util.convert_if_relative_url(url, link)
    link = util.remove_fragment(link)
    # Hardcoded filter
    if link[-11:] == "Restaurants":
        if tag["name"] != '':
            if link not in links:
                links.append(link)

for link in links:
    print(link)
'''


##### REFERENCE #####
'''
# All links
<a class=" link__09f24__1MGLa photo-box-link__09f24__28L0f link-color--blue-dark__09f24__tK18E link-size--default__09f24__QvrjA" href="/biz/boxcar-bettys-chicago-2?osq=Restaurants" target="" name="" rel="">
<a class=" link__09f24__1MGLa link-color--inherit__09f24__3Cplm link-size--default__09f24__QvrjA" href="/search?cflt=sandwiches&amp;find_desc=Restaurants&amp;find_loc=Chicago%2C+IL" target="" name="" rel="" role="link">

# Repeated links
'https://www.yelp.com/biz/the-delta-chicago?osq=Restaurants'
'https://www.yelp.com/biz/the-delta-chicago?hrid=qtOXI4YDVJNFHs4GvZqGuA&osq=Restaurants'

<a class=" link__09f24__1MGLa link-color--inherit__09f24__3Cplm link-size--inherit__09f24__3Javq" href="/biz/penumbra-chicago?osq=Restaurants" target="" name="Penumbra" rel="">
<a class=" link__09f24__1MGLa link-color--blue-dark__09f24__tK18E link-size--inherit__09f24__3Javq" href="/biz/penumbra-chicago?hrid=_DHfzbvVXSfBoHjJHAx8kg&amp;osq=Restaurants" target="" name="" rel="">
'''
